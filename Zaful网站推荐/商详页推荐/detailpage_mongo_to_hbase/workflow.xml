<workflow-app name="recommend_detailpage_al2rec_zaful-wf" 
	xmlns="uri:oozie:workflow:0.5">

	<start to="wait_fork" />

	<fork name = "wait_fork">
   		<path start="wait_mongodb_w2v_detail" />
   		<path start="wait_mongodb_abtestv5_detail" />
   </fork>

	<action name="wait_mongodb_w2v_detail">
		<spark xmlns="uri:oozie:spark-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>jobTracker</name>
					<value>${jobTracker}</value>
				</property>
				<property>
					<name>nameNode</name>
					<value>${nameNode}</value>
				</property>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
				<property>
					<name>oozie.use.system.libpath</name>
					<value>true</value>
				</property>
				<property>
					<name>DATE</name>
					<value>${DATE}</value>
				</property>
			</configuration>
			<master>yarn</master>
			<mode>cluster</mode>
			<name>AlgorithmRedisFlagCheck</name>
			<class>com.glbg.ai.recommend_gb.AlgorithmRedisFlagCheck</class>
			<jar>hdfs://glbgnameservice/user/oozie/oozie-apps/hw_bigdata_dw/dw_proj/dw_zaful_recommend/recommend_zaful_detailpage/algorithm_to_recommend/lib/recommend-gb-1.0-SNAPSHOT-jar-with-dependencies.jar</jar>
			<spark-opts>--files hdfs://glbgnameservice/user/oozie/share/conf/hive-site.xml --queue root.ai.offline --executor-memory 4g --driver-memory 2g --driver-cores 2 --num-executors 10 --executor-cores 1 --conf spark.storage.memoryFraction=0.05 --conf spark.shuffle.memoryFraction=0.75 --conf spark.sql.shuffle.partitions=200 --conf spark.default.parallelism=200 --conf spark.yarn.executor.memoryOverhead=1024</spark-opts>
			<arg>algorithm_task_status</arg>
			<arg>zaful_detail_w2v</arg>
			<arg>algorithm_task_status_old</arg>
			<arg>zaful_detail_w2v</arg>
		</spark>
		<ok to="zaful_detail_w2v"/>
		<error to="wait_join"/>
	</action>

	<action name="zaful_detail_w2v">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
				<property>
					<name>YEAR</name>
					<value>${YEAR}</value>
				</property>
				<property>
					<name>MONTH</name>
					<value>${MONTH}</value>
				</property>
				<property>
					<name>DAY</name>
					<value>${DAY}</value>
				</property>
			</configuration>
			<main-class>com.globalegrow.hadoop.mongotohive.MongoToHivePlatformMR</main-class>
			<arg>/user/hive/warehouse/dw_zaful_recommend.db/result_detail_page_abtest_w2v/year=${YEAR}/month=${MONTH}/day=${DAY}/</arg>
			<arg>172.31.27.16</arg>
			<arg>27017</arg>
			<arg>recommender_online</arg>
			<arg>zaful_detail_w2v</arg>
		</java>
		<ok to="apl_result_detailpage_zaful_abtest_w2v_tohbase_new" />
		<error to="failed_mail" />
	</action>

	<action name="apl_result_detailpage_zaful_abtest_w2v_tohbase_new">
		<spark xmlns="uri:oozie:spark-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>jobTracker</name>
					<value>${jobTracker}</value>
				</property>
				<property>
					<name>nameNode</name>
					<value>${nameNode}</value>
				</property>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
				<property>
					<name>oozie.use.system.libpath</name>
					<value>true</value>
				</property>
				<property>
					<name>DATE</name>
					<value>${DATE}</value>
				</property>
			</configuration>
			<master>yarn</master>
			<mode>cluster</mode>
			<name>HBaseRunner(apl_result_detailpage_zaful_abtest_w2v)</name>
			<class>com.glbg.ai.recommend_gb.RecommendResult2Hbase</class>
			<jar>hdfs://glbgnameservice/user/oozie/oozie-apps/hw_bigdata_dw/dw_proj/dw_zaful_recommend/recommend_zaful_detailpage/algorithm_to_recommend/lib/recommend-gb-1.0-SNAPSHOT-jar-with-dependencies.jar</jar>
			<spark-opts>--files hdfs://glbgnameservice/user/oozie/share/conf/hive-site.xml --queue root.ai.offline --executor-memory 4g --driver-memory 2g --driver-cores 2 --num-executors 10 --executor-cores 1 --conf spark.storage.memoryFraction=0.05 --conf spark.shuffle.memoryFraction=0.75 --conf spark.sql.shuffle.partitions=200 --conf spark.default.parallelism=200 --conf spark.yarn.executor.memoryOverhead=1024</spark-opts>
			<arg>apl_result_detailpage_zaful_abtest_w2v</arg>
			<arg>dw_zaful_recommend.result_detail_page_abtest_w2v</arg>
			<arg>0,1</arg>
			<arg>${DATE}</arg>
			<arg>YES</arg>
			<arg>YES</arg>
		</spark>
		<ok to="wait_join"/>
		<error to="failed_mail"/>
	</action>

	<action name="wait_mongodb_abtestv5_detail">
		<spark xmlns="uri:oozie:spark-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>jobTracker</name>
					<value>${jobTracker}</value>
				</property>
				<property>
					<name>nameNode</name>
					<value>${nameNode}</value>
				</property>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
				<property>
					<name>oozie.use.system.libpath</name>
					<value>true</value>
				</property>
				<property>
					<name>DATE</name>
					<value>${DATE}</value>
				</property>
			</configuration>
			<master>yarn</master>
			<mode>cluster</mode>
			<name>AlgorithmRedisFlagCheck</name>
			<class>com.glbg.ai.recommend_gb.AlgorithmRedisFlagCheck</class>
			<jar>hdfs://glbgnameservice/user/oozie/oozie-apps/hw_bigdata_dw/dw_proj/dw_zaful_recommend/recommend_zaful_detailpage/algorithm_to_recommend/lib/recommend-gb-1.0-SNAPSHOT-jar-with-dependencies.jar</jar>
			<spark-opts>--files hdfs://glbgnameservice/user/oozie/share/conf/hive-site.xml --queue root.ai.offline --executor-memory 4g --driver-memory 2g --driver-cores 2 --num-executors 10 --executor-cores 1 --conf spark.storage.memoryFraction=0.05 --conf spark.shuffle.memoryFraction=0.75 --conf spark.sql.shuffle.partitions=200 --conf spark.default.parallelism=200 --conf spark.yarn.executor.memoryOverhead=1024</spark-opts>
			<arg>algorithm_task_status</arg>
			<arg>result_detail_page_abtest_v5</arg>
			<arg>algorithm_task_status_old</arg>
			<arg>result_detail_page_abtest_v5</arg>
		</spark>
		<ok to="result_detail_page_abtest_v5" />
		<error to="wait_join" />
	</action>

	<action name="result_detail_page_abtest_v5">
		<java>
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
				<property>
					<name>YEAR</name>
					<value>${YEAR}</value>
				</property>
				<property>
					<name>MONTH</name>
					<value>${MONTH}</value>
				</property>
				<property>
					<name>DAY</name>
					<value>${DAY}</value>
				</property>
			</configuration>
			<main-class>com.globalegrow.hadoop.mongotohive.MongoToHivePlatformMR</main-class>
			<arg>/user/hive/warehouse/dw_zaful_recommend.db/result_detail_page_abtest_v5/year=${YEAR}/month=${MONTH}/day=${DAY}/</arg>
			<arg>172.31.27.16</arg>
			<arg>27017</arg>
			<arg>recommender_online</arg>
			<arg>result_detail_page_abtest_v5</arg>
		</java>
		<ok to="apl_result_detailpage_zaful_abtest_v5_tohbase_new" />
		<error to="failed_mail" />
	</action>

	<action name="apl_result_detailpage_zaful_abtest_v5_tohbase_new">
		<spark xmlns="uri:oozie:spark-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>jobTracker</name>
					<value>${jobTracker}</value>
				</property>
				<property>
					<name>nameNode</name>
					<value>${nameNode}</value>
				</property>
				<property>
					<name>mapred.job.queue.name</name>
					<value>${queueName}</value>
				</property>
				<property>
					<name>oozie.use.system.libpath</name>
					<value>true</value>
				</property>
				<property>
					<name>DATE</name>
					<value>${DATE}</value>
				</property>
			</configuration>
			<master>yarn</master>
			<mode>cluster</mode>
			<name>HBaseRunner(apl_result_detailpage_zaful_abtest_v5)</name>
			<class>com.glbg.ai.recommend_gb.RecommendResult2Hbase</class>
			<jar>hdfs://glbgnameservice/user/oozie/oozie-apps/hw_bigdata_dw/dw_proj/dw_zaful_recommend/recommend_zaful_detailpage/algorithm_to_recommend/lib/recommend-gb-1.0-SNAPSHOT-jar-with-dependencies.jar</jar>
			<spark-opts>--files hdfs://glbgnameservice/user/oozie/share/conf/hive-site.xml --queue root.ai.offline --executor-memory 4g --driver-memory 2g --driver-cores 2 --num-executors 10 --executor-cores 1 --conf spark.storage.memoryFraction=0.05 --conf spark.shuffle.memoryFraction=0.75 --conf spark.sql.shuffle.partitions=200 --conf spark.default.parallelism=200 --conf spark.yarn.executor.memoryOverhead=1024</spark-opts>
			<arg>apl_result_detailpage_zaful_abtest_v5</arg>
			<arg>dw_zaful_recommend.result_detail_page_abtest_v5</arg>
			<arg>0,1</arg>
			<arg>${DATE}</arg>
			<arg>YES</arg>
			<arg>YES</arg>
		</spark>
		<ok to="wait_join"/>
		<error to="failed_mail"/>
	</action>

	<join name = "wait_join" to = "end" />

	<action name="failed_mail">
		<email xmlns="uri:oozie:email-action:0.2">
			<to>yuhui@globalegrow.com</to>
			<subject>recommend_detailpage_zaful-wf failed</subject>
			<body>recommend_detailpage_zaful-wf-wf failed ;${timestamp()} </body>
		</email>
		<ok to="kill" />
		<error to="kill" />
	</action>

	<kill name="kill">
		<message>Job failed, error
			message[${wf:errorMessage(wf:lastErrorNode())}]</message>
	</kill>
	
	<end name="end" />
	
</workflow-app>